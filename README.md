# è§†è§‰è¯­è¨€å¤§æ¨¡å‹å¼•å¯¼çš„å¤šæ¨¡æ€å›¾åƒèåˆ
å¤ç°çš„ä»£ç å’Œæ•°æ®é›†æ¥æºäºè®ºæ–‡ ***Image Fusion via Vision-Language Model (ICML 2024).***

## ğŸŠé“¾æ¥
- [*[æ¨¡å‹æƒé‡]*](https://pan.baidu.com/s/1CT7I4YrhhgCUnuInaau05w?pwd=q45e)  
- [*[æ•°æ®é›†ï¼ˆä½¿ç”¨å‰200å¯¹ï¼‰]*](https://pan.baidu.com/s/1acy8qxiDxSXChMisoh8sgQ?pwd=r3rs)  

## ğŸŒUsage
### è®­ç»ƒ
**1. è™šæ‹Ÿç¯å¢ƒé…ç½®**
```
conda create -n FILM python=3.8
conda activate FILM
#æ³¨æ„jittoråº“å®‰è£…
sudo apt install python3.8-dev libomp-dev
python3.8 -m pip install jittor
python3.8 -m jittor.test.test_example
pip install -r requirements.txt
```

**2. æ•°æ®å‡†å¤‡ä¸é¢„å¤„ç†**

ä¸‹è½½å¥½ä¸Šè¿°é“¾æ¥ä¸­çš„æ•°æ®é›†åï¼ŒæŒ‰ç…§ä¸‹è½½çš„å±‚çº§å…³ç³»æ”¾åœ¨VLFDatasetæ–‡ä»¶å¤¹ä¸­ï¼Œç„¶åè¿è¡Œä¸‹é¢çš„å‘½ä»¤
Run 
```
python data_process.py
``` 
æ‚¨å°†å¾—åˆ°è®­ç»ƒçš„H5æ–‡ä»¶å­˜æ”¾åœ¨ç›®å½• ``'./VLFDataset_h5/MSRS_train.h5'``ã€‚å…¶ä¸­ï¼Œæ¯ä¸ªH5æ–‡ä»¶éƒ½åŒ…å«ä¸‰ä¸ªå­—æ®µimageAã€imageBã€text
```
text.shapeï¼š(1, 149, 768)
imageA.shapeï¼š(1, 288, 384)
imageB.shapeï¼š(1, 288, 384)
``` 

**4. FILM è®­ç»ƒ**

Run 
```
python train.py
``` 
è®­ç»ƒç»“æœå°†å­˜å‚¨åœ¨ './exp/' æ–‡ä»¶å¤¹ä¸­ã€‚ä¸‹ä¸€çº§å­æ–‡ä»¶å¤¹å†…éƒ¨åŒ…å«ä¸‰ä¸ªæ–‡ä»¶å¤¹ï¼ˆ'code'ã€'model' å’Œ 'pic_fusion'ï¼‰ï¼Œä»¥åŠä¸€ä¸ªæ—¥å¿—æ–‡ä»¶å’Œä¸€ä¸ªè®°å½•å‚æ•°çš„ JSON æ–‡ä»¶ã€‚å…¶ä¸­ï¼š

'code' æ–‡ä»¶å¤¹ç”¨äºä¿å­˜è¯¥æ¬¡è®­ç»ƒå¯¹åº”çš„æ¨¡å‹æ–‡ä»¶å’Œè®­ç»ƒæ–‡ä»¶ï¼›

'model' æ–‡ä»¶å¤¹ç”¨äºä¿å­˜è®­ç»ƒè¿‡ç¨‹ä¸­æ¯ä¸ª epoch çš„æ¨¡å‹æƒé‡ï¼›

'pic_fusion' æ–‡ä»¶å¤¹ç”¨äºä¿å­˜æ¯ä¸ªè®­ç»ƒ epoch ä¸­å‰ä¸¤ä¸ªæ‰¹æ¬¡çš„åŸå§‹å›¾åƒåŠèåˆç»“æœã€‚

åœ¨æ¨¡å‹ä¿å­˜æ–¹é¢ï¼Œjittorå’Œpytorchæœ‰æ‰€åŒºåˆ«ï¼Œå› æ­¤è¿›è¡Œæ”¹åŠ¨
```
jt.save(checkpoint, os.path.join(model_dir, f'ckpt_{epoch+1}.pkl')) #ä¿å­˜
model.load(jt.load(ckpt_path)["model"]) #åŠ è½½
``` 
å³ä¿å­˜çš„æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œé”®æ˜¯å‚æ•°åï¼Œå€¼æ˜¯ Jittor çš„ jt.Varå¯¹è±¡ã€‚
### æµ‹è¯•

**1. é¢„è®­ç»ƒæ¨¡å‹**

é¢„è®­ç»ƒæ¨¡å‹å¯åœ¨- [*[é“¾æ¥]*](https://pan.baidu.com/s/1CT7I4YrhhgCUnuInaau05w?pwd=q45e)ä¸­æ‰¾åˆ°ã€‚ç”¨äºå¤„ç†çº¢å¤–-å¯è§å…‰èåˆï¼ˆIVFï¼‰ä»»åŠ¡ï¼Œå…¶ä»–çš„å¤šæ›å…‰å›¾åƒèåˆã€å¤šèšç„¦å›¾åƒèåˆã€å’ŒåŒ»å­¦å›¾åƒèåˆç­‰ä»»åŠ¡ä¹Ÿæ˜¯ä¸€æ ·çš„æµ‹è¯•ä»£ç ã€‚

**2. æµ‹è¯•æ•°æ®é›†**

é€šè¿‡ä¸Šé¢æä¾›çš„æ•°æ®é›†ä¸‹è½½é“¾æ¥- [*[æ•°æ®é›†ï¼ˆä½¿ç”¨å‰200å¯¹ï¼‰]*](https://pan.baidu.com/s/1acy8qxiDxSXChMisoh8sgQ?pwd=r3rs)æ˜¯åŒ…æ‹¬æµ‹è¯•é›†çš„ï¼Œåœ¨data_process.pyæ–‡ä»¶ä¸­ï¼Œä¿®æ”¹å¦‚ä¸‹ï¼š
```
img_text_path = 'VLFDataset'
h5_path = "VLFDataset_h5"
os.makedirs(h5_path, exist_ok=True)
task_name = 'IVF'
dataset_name = 'MSRS'
dataset_mode = 'test'
size = 'small'
``` 

**3. Results in Our Paper**

If you want to infer with our FILM and obtain the fusion results in our paper, please run 
```
python test.py
``` 
to perform image fusion. The output fusion results will be saved in the ``'./test_output/{Dataset_name}/Gray'``  folder. If you want to test using your own trained model, you can set the path of the model you want to load as ``'ckpt_path'`` before the model weights are loaded in ``'test.py'``.

The output for IVF is:

```
================================================================================
The test result of MSRS:
                 EN      SD      SF      AG     VIFF     Qabf    
FILM            6.72	43.64	11.55	3.72	1.06	0.70    
================================================================================

================================================================================
The test result of RoadScene:
                 EN      SD      SF      AG     VIFF     Qabf    
FILM            7.43	49.26	17.33	6.59	0.69	0.62    
================================================================================

================================================================================
The test result of M3FD:
                 EN      SD      SF      AG     VIFF     Qabf    
FILM            7.09	41.52	16.77	5.55	0.83	0.67    
================================================================================
```
which can match the results in Table 1 in our original paper.

The output for MIF is:

```
================================================================================
The test result of Harvard:
                 EN      SD      SF      AG     VIFF     Qabf    
FILM            4.74	65.23	23.36	6.19	0.78	0.76    
================================================================================
```
which can match the results in Table 2 in our original paper.

The output for MEF is:

```
================================================================================
The test result of SICE:
                 EN      SD      SF      AG     VIFF     Qabf    
FILM            7.07	54.22	19.39	5.14	1.05	0.79    
================================================================================

================================================================================
The test result of MEFB:
                 EN      SD      SF      AG     VIFF     Qabf    
FILM            7.32	68.98	20.94	6.14	0.98	0.77    
================================================================================
```
which can match the results in Table 3 in our original paper.

The output for MFF is:

```
================================================================================
The test result of RealMFF:
                 EN      SD      SF      AG     VIFF     Qabf    
FILM            7.11	54.97	15.62	5.43	1.11	0.76   
================================================================================

================================================================================
The test result of Lytro:
                 EN      SD      SF      AG     VIFF     Qabf    
FILM            7.56	59.15	19.57	6.97	0.98	0.74    
================================================================================
```
which can match the results in Table 4 in our original paper.

## ğŸ“ Vision-Language Fusion (VLF) Dataset
Considering the high computational cost of invoking various vision-language components, and to facilitate subsequent research on image fusion based on vision-language models, we propose the **VLF Dataset**. This dataset encompasses paired paragraph descriptions generated by ChatGPT, covering all image pairs from the training and test sets of the eight widely-used fusion datasets.

These include

* **Infrared-visible image fusion (IVF)**: [MSRS](https://github.com/Linfeng-Tang/MSRS), [MÂ³FD](https://github.com/JinyuanLiu-CV/TarDAL), and [RoadScene](https://github.com/hanna-xu/RoadScene) datasets;
* **Medical image fusion (MIF)**: [Harvard](http://www.med.harvard.edu/AANLIB/home.html) dataset;
* **Multi-exposure image fusion (MEF)**: [SICE](https://github.com/csjcai/SICE) and [MEFB](https://github.com/xingchenzhang/MEFB) datasets;
* **Multi-focus image fusion (MFF)**: [RealMFF](https://github.com/Zancelot/Real-MFF) and [Lytro](http://mansournejati.ece.iut.ac.ir/content/lytro-multi-focus-dataset) datasets;

**The dataset is available for download via [Google Drive](https://drive.google.com/drive/folders/1JPNbh-iFhkbr35FDUOYEN4WE4LnxY954?usp=sharing).**

**More visualizations and illustrations of the VLF Dataset can be found on our [Project Homepage](https://zhaozixiang1228.github.io/Project/IF-FILM/).**

<u>**[Notice]**</u>:  
Considering the immense workload involved in creating this dataset, we have opened a [Google Form](https://forms.gle/1kTAS15DktRPLs5BA) for error correction feedback. Please provide your suggestions for correcting any errors in the VLF dataset. If you have any questions regarding the Google Form, please contact [Zixiang](https://zhaozixiang1228.github.io/) via email.


## ğŸ™Œ Fusion via vIsion-Language Model (FILM)

#### Workflow for our FILM

<img src="images\1.png" width="70%" align=center />

#### Detailed Architecture of FILM

<img src="images\2.png" width="70%" align=center />

#### Visualization of the VLF dataset

<img src="images\3.png" width="90%" align=center />

## ğŸ“ Experimental Results

### Infrared-visible image fusion (IVF)

#### Qualitative fusion results:
<img src="images\RS_06570.png" width="70%" align=center />

#### Quantitative fusion results:
<img src="images\R1.png" width="90%" align=center />

### Medical image fusion (MIF)

#### Qualitative fusion results:
<img src="images\Harvard_MRI_PET_19.png" width="50%" align=center />

#### Quantitative fusion results:
<img src="images\R2.png" width="40%" align=center />

### Multi-exposure image fusion (MEF)

#### Qualitative fusion results:
<img src="images\SICE_076.png" width="70%" align=center />

#### Quantitative fusion results:
<img src="images\R3.png" width="70%" align=center />

### Multi-focus image fusion (MFF)

#### Qualitative fusion results:
<img src="images\RealMFF_126.png" width="70%" align=center />

#### Quantitative fusion results:
<img src="images\R4.png" width="70%" align=center />

## â­ Star History

[![Star History Chart](https://api.star-history.com/svg?repos=Zhaozixiang1228/IF-FILM&type=Date)](https://star-history.com/#Zhaozixiang1228/IF-FILM&Date)

## ğŸ“– Related Work

- [*Equivariant Multi-Modality Image Fusion.*](https://arxiv.org/abs/2305.11443) **CVPR 2024**.    
Zixiang Zhao, Haowen Bai, Jiangshe Zhang, Yulun Zhang, Kai Zhang, Shuang Xu, Dongdong Chen, Radu Timofte, Luc Van Gool.

- [*DDFM: Denoising Diffusion Model for Multi-Modality Image Fusion.* ](https://arxiv.org/abs/2303.06840) **ICCV 2023 (Oral)**.    
Zixiang Zhao, Haowen Bai, Yuanzhi Zhu, Jiangshe Zhang, Shuang Xu, Yulun Zhang, Kai Zhang, Deyu Meng, Radu Timofte, Luc Van Gool. 

- [*CDDFuse: Correlation-Driven Dual-Branch Feature Decomposition for Multi-Modality Image Fusion.*](https://arxiv.org/abs/2211.14461) **CVPR 2023**.    
Zixiang Zhao, Haowen Bai, Jiangshe Zhang, Yulun Zhang, Shuang Xu, Zudi Lin, Radu Timofte, Luc Van Gool.

- [*DIDFuse: Deep Image Decomposition for Infrared and Visible Image Fusion.*](https://arxiv.org/abs/2305.11443) **IJCAI 2020**.    
Zixiang Zhao, Shuang Xu, Chunxia Zhang, Junmin Liu, Jiangshe Zhang and Pengfei Li.

- [*Efficient and Model-Based Infrared and Visible Image Fusion via Algorithm Unrolling.*](https://ieeexplore.ieee.org/document/9416456.) **IEEE TCSVT 2021**.    
Zixiang Zhao, Shuang Xu, Jiangshe Zhang, Chengyang Liang, Chunxia Zhang and Junmin Liu.

<!-- - Zixiang Zhao, Jiangshe Zhang, Haowen Bai, Yicheng Wang, Yukun Cui, Lilun Deng, Kai Sun, Chunxia Zhang, Junmin Liu, Shuang Xu. *Deep Convolutional Sparse Coding Networks for Interpretable Image Fusion.* **CVPR Workshop 2023**. https://robustart.github.io/long_paper/26.pdf.

- Zixiang Zhao, Shuang Xu, Chunxia Zhang, Junmin Liu, Jiangshe Zhang. *Bayesian fusion for infrared and visible images.* **Signal Processing**. https://doi.org/10.1016/j.sigpro.2020.107734. -->

